{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RByeKCfdaSZ7"
   },
   "source": [
    "# LELA32051 Training a Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4310,
     "status": "ok",
     "timestamp": 1637783404883,
     "user": {
      "displayName": "Colin Bannard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu3NcIkMWzsy6zxo7AXqwviYA_hgjuzVq_zKWseQ=s64",
      "userId": "01716265927303848317"
     },
     "user_tz": 0
    },
    "id": "x1U85sASKSul",
    "outputId": "c1e412a2-6d14-43e5-e122-e9b57cd17db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-20 10:58:07--  https://www.dropbox.com/s/4u35bn58ryrnpy8/CL_Week_4_Materials.zip\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/4u35bn58ryrnpy8/CL_Week_4_Materials.zip [following]\n",
      "--2022-10-20 10:58:08--  https://www.dropbox.com/s/raw/4u35bn58ryrnpy8/CL_Week_4_Materials.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com/cd/0/inline/BvK2rGcacnycL5c-bA7XtBpn_174p4VerGIDEQXCCEVOxoDInqwVE95JjDLQZdAY1ltoUwUStczE-I5bLA7WVUGDWCsT8VrpFNWUgtBe6NhJf5bMm9NiTlKS5zENhsXlxR-sK_Jhfa7eyTalg70p8BFFJpn41wNWBixX62Pod9bLVQ/file# [following]\n",
      "--2022-10-20 10:58:08--  https://uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com/cd/0/inline/BvK2rGcacnycL5c-bA7XtBpn_174p4VerGIDEQXCCEVOxoDInqwVE95JjDLQZdAY1ltoUwUStczE-I5bLA7WVUGDWCsT8VrpFNWUgtBe6NhJf5bMm9NiTlKS5zENhsXlxR-sK_Jhfa7eyTalg70p8BFFJpn41wNWBixX62Pod9bLVQ/file\n",
      "Resolving uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com (uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com)... 162.125.65.15\n",
      "Connecting to uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com (uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/BvJyorxbzOV-EFufwSy7t6Ze7GztLGNGYkXbEtnBks_3LCr2tCO0ZrtzoyvaxTNkWGfUVIJeOmq-OOzD6oMO3ylm_lBt-75S-ek11YRpMV-idyaXv-6Nm5X_LVn2X6Fxut8m0WxnJFUfP9ade9Z-WGQlkRZSpgkIG5LUn0hxIP-DxSO5ad2tAVhZ80ZOXB1y112UeVmomoq-yyITuIjlsEoXbUJUOL_ORdhlrhepyEBjK2BfbaaMuiLguzhSYZR_i2NqT9n75ZDRPkKDU4NkFh03rn3saLAKohwO-XZsz8jIVYQaEk-wiuMvcIZlWQTu8CWKHlqQhH62CEuS3NhnEM73zxZnhi1PfiH3lqTQ_sOYPqXk4O0Rqg7nDpZPXiXf3FZSmpnxQPI2x0u-2NNS3un2PUAVYztCrEaAs4orj_KGpA/file [following]\n",
      "--2022-10-20 10:58:09--  https://uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com/cd/0/inline2/BvJyorxbzOV-EFufwSy7t6Ze7GztLGNGYkXbEtnBks_3LCr2tCO0ZrtzoyvaxTNkWGfUVIJeOmq-OOzD6oMO3ylm_lBt-75S-ek11YRpMV-idyaXv-6Nm5X_LVn2X6Fxut8m0WxnJFUfP9ade9Z-WGQlkRZSpgkIG5LUn0hxIP-DxSO5ad2tAVhZ80ZOXB1y112UeVmomoq-yyITuIjlsEoXbUJUOL_ORdhlrhepyEBjK2BfbaaMuiLguzhSYZR_i2NqT9n75ZDRPkKDU4NkFh03rn3saLAKohwO-XZsz8jIVYQaEk-wiuMvcIZlWQTu8CWKHlqQhH62CEuS3NhnEM73zxZnhi1PfiH3lqTQ_sOYPqXk4O0Rqg7nDpZPXiXf3FZSmpnxQPI2x0u-2NNS3un2PUAVYztCrEaAs4orj_KGpA/file\n",
      "Reusing existing connection to uc3b2c1ad754820b8c90413435b8.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14250378 (14M) [application/zip]\n",
      "Saving to: ‘CL_Week_4_Materials.zip’\n",
      "\n",
      "CL_Week_4_Materials  28%[====>               ]   3.87M  91.6KB/s    eta 88s    "
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/4u35bn58ryrnpy8/CL_Week_4_Materials.zip\n",
    "!unzip -q CL_Week_4_Materials.zip\n",
    "!cp -r CL_Week_4_Materials/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5946,
     "status": "ok",
     "timestamp": 1637783430644,
     "user": {
      "displayName": "Colin Bannard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu3NcIkMWzsy6zxo7AXqwviYA_hgjuzVq_zKWseQ=s64",
      "userId": "01716265927303848317"
     },
     "user_tz": 0
    },
    "id": "UqFmkcr0oiYY"
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "from nn_tools import Vocabulary, ReviewVectorizer, ReviewDataset, ReviewClassifier\n",
    "from nn_tools2 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYratCznHUbT"
   },
   "source": [
    "### Create Dummy Data for a classifier\n",
    "Imagine a set of one word reviews of products using a vocabulary  with two semantic *dimensions* and two possible labels (negative or positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PomHIMLiEYtv"
   },
   "outputs": [],
   "source": [
    "WORD1_CENTER = (3, 3)\n",
    "WORD2_CENTER = (3, -2)\n",
    "def get_toy_data(batch_size, w1_center=WORD1_CENTER, w2_center=WORD2_CENTER):\n",
    "      x_data = []\n",
    "      y_targets = np.zeros(batch_size)\n",
    "      for batch_i in range(batch_size):\n",
    "          if np.random.random() > 0.5:\n",
    "              x_data.append(np.random.normal(loc=w1_center))\n",
    "          else:\n",
    "              x_data.append(np.random.normal(loc=w2_center))\n",
    "              y_targets[batch_i] = 1\n",
    "      return torch.tensor(x_data, dtype=torch.float32), torch.tensor(y_targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO1jSu46E-5W"
   },
   "source": [
    "### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NaDUzmMEyTt"
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "x_data, y_truth = get_toy_data(batch_size=1000)\n",
    "\n",
    "x_data = x_data.data.numpy()\n",
    "y_truth = y_truth.data.numpy()\n",
    "\n",
    "left_x = []\n",
    "right_x = []\n",
    "left_colors = []\n",
    "right_colors =  []\n",
    "\n",
    "for x_i, y_true_i in zip(x_data, y_truth):\n",
    "    color = 'black'\n",
    "\n",
    "    if y_true_i == 0:\n",
    "        left_x.append(x_i)\n",
    "        left_colors.append(color)\n",
    "\n",
    "    else:\n",
    "        right_x.append(x_i)\n",
    "        right_colors.append(color)\n",
    "\n",
    "left_x = np.stack(left_x)\n",
    "right_x = np.stack(right_x)\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "\n",
    "ax.scatter(left_x[:, 0], left_x[:, 1], color=left_colors, marker='*', s=100)\n",
    "ax.scatter(right_x[:, 0], right_x[:, 1], facecolor='white', edgecolor=right_colors, marker='o', s=100)\n",
    "\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1637783446125,
     "user": {
      "displayName": "Colin Bannard",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggu3NcIkMWzsy6zxo7AXqwviYA_hgjuzVq_zKWseQ=s64",
      "userId": "01716265927303848317"
     },
     "user_tz": 0
    },
    "id": "SQA_P6NyEyYR"
   },
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    \"\"\" A Perceptron is one Linear layer \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): size of the input features\n",
    "        \"\"\"\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        \"\"\"The forward pass of the MLP\n",
    "\n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, 1)\n",
    "        \"\"\"\n",
    "        return torch.sigmoid(self.fc1(x_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vt4o2Q-IX8N"
   },
   "source": [
    "We can then train that Perceptron to assign labels to our 1 word reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "input_dim = 2\n",
    "\n",
    "batch_size = 1000\n",
    "n_epochs = 12\n",
    "n_batches = 5\n",
    "\n",
    "seed = 1337\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "perceptron = Perceptron(input_dim=input_dim)\n",
    "optimizer = optim.Adam(params=perceptron.parameters(), lr=lr)\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "x_data_static, y_truth_static = get_toy_data(batch_size)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "visualize_results(perceptron, x_data_static, y_truth_static, ax=ax, title='Initial Model State')\n",
    "plt.axis('off')\n",
    "\n",
    "change = 1.0\n",
    "last = 10.0\n",
    "epsilon = 1e-3\n",
    "epoch = 0\n",
    "while change > epsilon or epoch < n_epochs or last > 0.3:\n",
    "#for epoch in range(n_epochs):\n",
    "    for _ in range(n_batches):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_data, y_target = get_toy_data(batch_size)\n",
    "        y_pred = perceptron(x_data).squeeze()\n",
    "        loss = bce_loss(y_pred, y_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        change = abs(last - loss_value)\n",
    "        last = loss_value\n",
    "               \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "    visualize_results(perceptron, x_data_static, y_truth_static, ax=ax, epoch=epoch, \n",
    "                      title=f\"{loss_value}; {change}\")\n",
    "    plt.axis('off')\n",
    "    epoch += 1\n",
    "    #plt.savefig('epoch{}_toylearning.png'.format(epoch))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week_4_Seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
