{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada7675f",
   "metadata": {
    "id": "ada7675f"
   },
   "source": [
    "# LELA32051 Computational Linguistics Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243df473",
   "metadata": {},
   "source": [
    "## Some more on regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057638d",
   "metadata": {},
   "source": [
    "### Combining sub with groups\n",
    "The re.sub function and grouping become particularly powerful when they are combined. You can use parentheses to capture a particular substring within a pattern and then use it in your replacement string within sub. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91963cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_sentence = \"a young man came out of the garret in which he lodged in S. Place and walked slowly towards K. bridge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('([a-z]+)ed','is \\\\1ing',opening_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef174bd",
   "metadata": {},
   "source": [
    "Activity: Use sub combined with groups to convert the sentence \"man bites dog\" into \"dog bites man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"man bites dog\"\n",
    "print(re.sub('(man) (bites) (dog)','\\\\3 \\\\2 \\\\1',sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070f9e1",
   "metadata": {},
   "source": [
    "Activity: Use sub combined with groups to convert the sentence \"man strokes dog\" into \"dog is stroked by man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1588f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"man strokes dog\"\n",
    "print(re.sub('(man) (stroke)s (dog)','\\\\3 is \\\\2d by \\\\1',sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a7a48",
   "metadata": {},
   "source": [
    "### re.split()\n",
    "In week 1 we learned to tokenise a string using the string function split. re also has a split function. re.split() takes a regular expression as a first argument (unless you have a precompiled pattern) and a string as second argument, and split the string into tokens divided by all substrings matched by the regular expression. \n",
    "Can you improve on the following tokeniser? (clue: you might need to add a re.sub statement and you will need to know about escaping special characters as explained below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc85b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_sentence = \"On an exceptionally hot evening early in July a young man came out of the garret in which he lodged in S. Place and walked slowly, as though in hesitation, towards K. bridge.\"\n",
    "opening_sentence=re.sub('([a-z])\\.','\\\\1 .',opening_sentence)\n",
    "opening_sentence=re.sub('\\,',' ,',opening_sentence)\n",
    "to_split_on_word = re.compile(\" \")\n",
    "opening_sentence_new = to_split_on_word.split(opening_sentence)\n",
    "print(opening_sentence_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508cffb",
   "metadata": {},
   "source": [
    "### Escaping special characters\n",
    "We have learned about a number of character that have a special meaning in regular expressions (periods, dollar signs etc). We might sometimes want to search for these characters in strings. To do this we can \"escape\" the character using a backslash() as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02871a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\.\",opening_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5bc5b",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df58a8",
   "metadata": {},
   "source": [
    "Above we split a sentence into words. However most texts that we want to process have more than one sentence, so we also need to segment text into sentences. We will work with the first chapter of Crime and Punishment again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.gutenberg.org/files/2554/2554-0.txt \n",
    "f = open('2554-0.txt')\n",
    "raw = f.read()\n",
    "chapter_one = raw[5464:23725]\n",
    "chapter_one = re.sub('\\n',' ',chapter_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f08861",
   "metadata": {},
   "source": [
    "Just as for segmenting sentences into words, we can segment texts into sentence using the re.split function. If you run the code below you will get a list of words. What pattern could we use to get a list of sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_one=re.sub('([a-z])\\.','\\\\1 .',chapter_one)\n",
    "chapter_one=re.sub('\\,',' ,',chapter_one)\n",
    "to_split_on_sent = re.compile(\" +\\. +\")\n",
    "C_and_P_sentences = to_split_on_sent.split(chapter_one)\n",
    "print(C_and_P_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5345f",
   "metadata": {},
   "source": [
    "If we combine sentence segmentation and tokenising we can split an input text into a list of sentences, each of which is itself a list of words. But to do this we will need to learn about another important aspect of Python - the \"for loop\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91482388",
   "metadata": {},
   "source": [
    "# Iterating/for loops\n",
    "\n",
    "Humans reading texts do so one word and one sentence at a time. The same is often true for computers. This is most commonly performed using a \"for loop\". This can be straightforwardly implemented for lists. In the following code we iterate through the list printing each entry as we go. Note that the end=\"\" in the print statement tells it to end each printed token with a space rather than a new line which is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in opening_sentence_new:\n",
    "    print(word, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df10d5",
   "metadata": {},
   "source": [
    "You will notice that in the loop above the print statement is indented. We say that a statement that occurs within a loop is nested within that loop. Any statement that is nested inside another has to be indented in Python. The standard way to indent is to use 4 spaces, although you can also use a tab.\n",
    "\n",
    "Now we are able to loop/iterate through our sentences and tokenise each one in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ec3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_and_P = [] # this creates an empty list into which we can add the tokenised sentences\n",
    "for sent in C_and_P_sentences:\n",
    "    C_and_P.append(to_split_on_word.split(sent))\n",
    "print(C_and_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75769bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week_3_Seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
